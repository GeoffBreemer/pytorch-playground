{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats and Dogs using DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions and contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../datasets/kaggle_cats_and_dogs_subfolders\"\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 2\n",
    "CLASSIFIER_INPUT = 1024\n",
    "CLASSIFIER_HIDDEN = 500\n",
    "\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = 32\n",
    "NUM_EPOCH = 1\n",
    "LOG_EVERY = 25\n",
    "\n",
    "CATSDOGS_MEANS = (0.485, 0.456, 0.406)\n",
    "CATSDOGS_STDEVS = (0.229, 0.224, 0.225)\n",
    "\n",
    "CLASSES = [\"cat\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_img_prob(img, prob, y, classes, num_channels=1, means=None, stdevs=None):\n",
    "    \"\"\"Show an image and associated probability distribution\"\"\"\n",
    "    if prob is not None:\n",
    "        fig, (ax1, ax2) = plt.subplots(figsize=(6, 9), ncols=2)\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(figsize=(6, 9), ncols=1)\n",
    "\n",
    "    # Move the color dimension to the last column\n",
    "    img = img.numpy()\n",
    "    if num_channels == 3:\n",
    "        img = img.transpose((1, 2, 0))\n",
    "\n",
    "    # Denormalise the image\n",
    "    if means is not None and stdevs is not None:\n",
    "        img = stdevs * img + means\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "    # Show the image\n",
    "    if num_channels == 3:\n",
    "        ax1.imshow(img)\n",
    "    else:\n",
    "        ax1.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Show the probability distribution if provided\n",
    "    if prob is not None:\n",
    "        ax2.barh(np.arange(len(classes)), prob)\n",
    "        ax2.set_aspect(0.1)\n",
    "        ax2.set_yticks(np.arange(len(classes)))\n",
    "        ax2.set_yticklabels(classes)\n",
    "        ax2.set_title('Probabilities')\n",
    "        ax2.set_xlim(0, 1.0)\n",
    "        print(\"Prediction: {} - Actual: {}\".format(classes[prob.argmax()], classes[y.numpy()]))\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(model, loader):\n",
    "    \"\"\"Use the model to predict the class of the first image returned by the dataloader\"\"\"\n",
    "    # Grab the first batch\n",
    "    load_iter = iter(loader)\n",
    "    X, y = load_iter.next()\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logsoftmax = model.forward(X)\n",
    "        softmax = torch.exp(logsoftmax)\n",
    "    \n",
    "    softmax = softmax.numpy()\n",
    "\n",
    "    # Show one image\n",
    "    print(\"Softmax: {}\".format(softmax[0]))\n",
    "    view_img_prob(img=X[0], prob=softmax[0], y=y[0], classes=CLASSES,\n",
    "              num_channels=IMG_NUM_CHANNELS, means=CATSDOGS_MEANS, stdevs=CATSDOGS_STDEVS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image pre-processing\n",
    "train_transforms = transforms.Compose([transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=CATSDOGS_MEANS,\n",
    "                                                            std=CATSDOGS_STDEVS)\n",
    "                           ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "                            transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=CATSDOGS_MEANS,\n",
    "                                                            std=CATSDOGS_STDEVS)\n",
    "                           ])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train = datasets.ImageFolder(DATA_DIR + '/train', transform=train_transforms)\n",
    "test = datasets.ImageFolder(DATA_DIR + '/test', transform=test_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "imgs, labels = train_iter.next()\n",
    "\n",
    "view_img_prob(img=imgs[0], prob=None, y=labels[0], classes=CLASSES,\n",
    "              num_channels=IMG_NUM_CHANNELS, means=CATSDOGS_MEANS, stdevs=CATSDOGS_STDEVS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DenseNet (pre-trained)\n",
    "Model will be downloaded if not already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the trainable layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace the head, freeze parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the pre-trained weights of all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for layer in model.children():\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Create the new head tailored to the cats and dogs data set\n",
    "new_classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(CLASSIFIER_INPUT, CLASSIFIER_HIDDEN)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(CLASSIFIER_HIDDEN, NUM_CLASSES)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "# Replace the existing classifier\n",
    "model.classifier = new_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader):\n",
    "    \"\"\"Calculate loss and accuracy of the model on the entire validation set\"\"\"\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    count = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            if device != \"cpu\":\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                \n",
    "            output = model.forward(X_val)\n",
    "            loss += crit(output, y_val)\n",
    "            pred = torch.exp(output)\n",
    "\n",
    "            # Compare the actual labels to the argmax of the predictions\n",
    "            count += len(X_val)\n",
    "            correct += (y_val == pred.max(dim=-1)[1]).sum().item()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return loss/len(val_loader), correct/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, crit, opt, trn_loader, val_loader):\n",
    "    \"\"\"Train the model using the provided loss function, optimiser, training set\n",
    "    data loader and validation set data loader\"\"\"\n",
    "    start_time = time.time()\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Move the model to the GPU if available\n",
    "    if device != \"cpu\":\n",
    "        model.to(device)\n",
    "\n",
    "    for e in range(NUM_EPOCH):\n",
    "        total_correct = 0\n",
    "        total_count = 0\n",
    "        total_loss = 0\n",
    "        run_loss = 0\n",
    "        batch = 0\n",
    "        \n",
    "        print(\"\\nEpoch: {}/{}\".format(e+1, NUM_EPOCH))\n",
    "        print(\"=======================\")\n",
    "\n",
    "        for batch, (X, y) in enumerate(trn_loader, 0):\n",
    "            model.train()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            if device != \"cpu\":\n",
    "                X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Forward, backward and optimise\n",
    "            output = model.forward(X)\n",
    "            loss = crit(output, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            # Convert to probabilities\n",
    "            pred = torch.exp(output)\n",
    "            \n",
    "            # Keep track of metrics\n",
    "            correct = (y == pred.max(dim=-1)[1]).sum().item()\n",
    "            total_count += len(X)\n",
    "            total_correct += correct\n",
    "            total_loss += loss\n",
    "            run_loss += loss\n",
    "            \n",
    "            # Apply to the validation set\n",
    "            if batch % LOG_EVERY == (LOG_EVERY-1):\n",
    "                val_loss, val_acc = validate(model, device, val_loader)\n",
    "                lala = time.time()\n",
    "                # Print batch stats\n",
    "                print(\"Batch {:04d}/{:04d} - Trn_loss: {:.4f}, Trn_acc: {:6.2f}% -\".format(batch+1, len(trn_loader), run_loss/LOG_EVERY, 100*(correct/len(X))),\n",
    "                      \"Val_loss: {:.4f}, Val_acc: {:6.2f}%\".format(val_loss, 100*val_acc))\n",
    "                print(\"elapsed val: {}min\".format((time.time() - start_time)/60))\n",
    "                run_loss = 0\n",
    "                \n",
    "        # Print epoch stats\n",
    "        val_loss, val_acc = validate(model, device, val_loader)\n",
    "        print(\"\\n                  Trn_loss: {:.4f}, Trn_acc: {:6.2f}% -\".format(total_loss/len(trn_loader), 100*(total_correct/total_count)),\n",
    "              \"Val_loss: {:.4f}, Val_acc: {:6.2f}%\".format(val_loss, 100*val_acc))\n",
    "\n",
    "    # Move back to the CPU\n",
    "    if device != \"cpu\":\n",
    "        model.to(\"cpu\")\n",
    "        \n",
    "    print(\"\\nTraining complete, elapsed time: {:2f}min.\".format((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try using a GPU if one is present\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train using Adam\n",
    "opt = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "crit = nn.NLLLoss()\n",
    "\n",
    "# Don't attempt this on a CPU, it is extemely slow\n",
    "train_model(model, device, crit, opt, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the trained model to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_one(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
